{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cardiffnlp/xlm-t"
      ],
      "metadata": {
        "id": "lcerPVUFBT0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def process_language(language):\n",
        "    base_dir = \"/content/xlm-t/data/sentiment\"\n",
        "    lang_path = os.path.join(base_dir, language)\n",
        "\n",
        "    split = \"test\"\n",
        "    all_rows = []\n",
        "\n",
        "    with open(os.path.join(lang_path, f\"{split}_text.txt\"), encoding=\"utf-8\") as text_file, \\\n",
        "        open(os.path.join(lang_path, f\"{split}_labels.txt\"), encoding=\"utf-8\") as label_file:\n",
        "        texts = text_file.read().splitlines()\n",
        "        labels = label_file.read().splitlines()\n",
        "\n",
        "    for text, label in zip(texts, labels):\n",
        "        all_rows.append({\n",
        "            \"original_text\": text,\n",
        "            \"label\": label\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(all_rows)\n",
        "    df.to_csv(os.path.join(base_dir, f\"{language}.csv\"), index=False, encoding=\"utf-8\")"
      ],
      "metadata": {
        "id": "5jxWzG-8BVf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_language(\"hindi\")\n",
        "process_language(\"arabic\")\n",
        "process_language(\"french\")\n",
        "process_language(\"german\")\n",
        "process_language(\"italian\")\n",
        "process_language(\"portuguese\")\n",
        "process_language(\"spanish\")\n",
        "process_language(\"english\")"
      ],
      "metadata": {
        "id": "5CKICq16F8vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import torch\n",
        "\n",
        "# Preprocess text (username and link placeholders)\n",
        "def preprocess(text):\n",
        "    new_text = []\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)\n",
        "\n",
        "MODEL = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "config = AutoConfig.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    text = preprocess(text)\n",
        "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True)\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    labels = ['0', '1', '2'] # Negative; Neutral; Positive\n",
        "    predicted_label = labels[np.argmax(scores)]\n",
        "    return predicted_label, scores.tolist()\n",
        "\n",
        "\n",
        "# perform sentiment analysis for each dataset\n",
        "csv_dir = \"/content/xlm-t/data/sentiment\"\n",
        "output_dir = os.path.join(csv_dir, \"processed\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(csv_dir):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        input_path = os.path.join(csv_dir, filename)\n",
        "        df = pd.read_csv(input_path)\n",
        "\n",
        "        predicted_labels = []\n",
        "        confidence_scores = []\n",
        "\n",
        "        for text in df[\"original_text\"]:\n",
        "            label, raw_scores = analyze_sentiment(str(text))\n",
        "            predicted_labels.append(label)\n",
        "            rounded_scores = [round(score, 2) for score in raw_scores]\n",
        "            confidence_scores.append(rounded_scores)\n",
        "\n",
        "        df[\"predicted_label\"] = predicted_labels\n",
        "        df[\"confidence_negative\"] = [s[0] for s in confidence_scores]\n",
        "        df[\"confidence_neutral\"] = [s[1] for s in confidence_scores]\n",
        "        df[\"confidence_positive\"] = [s[2] for s in confidence_scores]\n",
        "\n",
        "        output_path = os.path.join(output_dir, filename.replace(\".csv\", \"_with_predictions.csv\"))\n",
        "        df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
        "        print(f\"Processed and saved: {output_path}\")"
      ],
      "metadata": {
        "id": "oUHoKkPXBzKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "input_dir = \"/content/xlm-t/data/sentiment/processed\"\n",
        "\n",
        "results = []\n",
        "\n",
        "for file in os.listdir(input_dir):\n",
        "    if file.endswith(\"_with_predictions.csv\"):\n",
        "        language = file.split(\"_\")[0]\n",
        "\n",
        "        df = pd.read_csv(os.path.join(input_dir, file))\n",
        "\n",
        "        if \"label\" in df.columns and \"predicted_label\" in df.columns:\n",
        "            correct = (df[\"label\"].astype(str).str.lower() == df[\"predicted_label\"].astype(str).str.lower()).sum()\n",
        "            total = len(df)\n",
        "            accuracy = round(correct / total, 3) if total > 0 else 0.0\n",
        "            results.append({\n",
        "                \"language\": language,\n",
        "                \"total\": total,\n",
        "                \"correct\": correct,\n",
        "                \"accuracy\": accuracy\n",
        "            })\n",
        "\n",
        "accuracy_df = pd.DataFrame(results)\n",
        "accuracy_df = accuracy_df.sort_values(by=\"accuracy\", ascending=False)\n",
        "\n",
        "print(accuracy_df)"
      ],
      "metadata": {
        "id": "mXz02pfkNW2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "input_dir = \"/content/xlm-t/data/sentiment/processed\"\n",
        "results = []\n",
        "\n",
        "labels = ['0', '1', '2']  # 0 = Negative, 1 = Neutral, 2 = Positive\n",
        "label_names = {'0': 'Negative', '1': 'Neutral', '2': 'Positive'}\n",
        "\n",
        "target_languages = ['spanish', 'french', 'italian', 'german']\n",
        "\n",
        "for file in os.listdir(input_dir):\n",
        "    if file.endswith(\"_with_predictions.csv\"):\n",
        "        language = file.split(\"_\")[0]\n",
        "\n",
        "        df = pd.read_csv(os.path.join(input_dir, file))\n",
        "\n",
        "        if \"label\" in df.columns and \"predicted_label\" in df.columns:\n",
        "            # Normalize labels to strings\n",
        "            df[\"label\"] = df[\"label\"].astype(str).str.strip()\n",
        "            df[\"predicted_label\"] = df[\"predicted_label\"].astype(str).str.strip()\n",
        "\n",
        "            correct = (df[\"label\"] == df[\"predicted_label\"]).sum()\n",
        "            total = len(df)\n",
        "            accuracy = round(correct / total, 3) if total > 0 else 0.0\n",
        "            results.append({\n",
        "                \"language\": language,\n",
        "                \"total\": total,\n",
        "                \"correct\": correct,\n",
        "                \"accuracy\": accuracy\n",
        "            })\n",
        "\n",
        "            # Plot confusion matrix for target languages\n",
        "            if language in target_languages:\n",
        "                cm = confusion_matrix(df[\"label\"], df[\"predicted_label\"], labels=labels)\n",
        "                disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[label_names[l] for l in labels])\n",
        "                disp.plot(cmap=\"Blues\", values_format='d')\n",
        "                plt.title(f\"Confusion Matrix - {language.capitalize()}\")\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "accuracy_df = pd.DataFrame(results)\n",
        "accuracy_df = accuracy_df.sort_values(by=\"accuracy\", ascending=False)\n",
        "\n",
        "print(\"\\nPer-language Accuracy:\")\n",
        "print(accuracy_df)"
      ],
      "metadata": {
        "id": "0EXKUYipT7rI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}